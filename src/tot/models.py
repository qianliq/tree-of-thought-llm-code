import os
import openai
import backoff 

completion_tokens = prompt_tokens = 0

api_key = os.getenv("OPENAI_API_KEY", "")
if api_key != "":
    openai.api_key = api_key
else:
    print("Warning: OPENAI_API_KEY is not set")
    
api_base = os.getenv("OPENAI_API_BASE", "")
if api_base != "":
    print("Warning: OPENAI_API_BASE is set to {}".format(api_base))
    openai.api_base = api_base

# å¤‡ç”¨ API é…ç½®
backup_api_key = os.getenv("BACKUP_OPENAI_API_KEY", "")
backup_api_base = os.getenv("BACKUP_OPENAI_API_BASE", "")

@backoff.on_exception(backoff.expo, openai.error.OpenAIError)
def completions_with_backoff(**kwargs):
    try:
        return openai.ChatCompletion.create(**kwargs)
    except openai.error.OpenAIError as e:
        error_message = str(e)
        error_type = type(e).__name__
        
        # å¯¹æ‰€æœ‰ OpenAI é”™è¯¯éƒ½å°è¯•ä½¿ç”¨å¤‡ç”¨ API
        if backup_api_key and backup_api_base:
            print(f"âš ï¸  é‡åˆ° API é”™è¯¯ ({error_type})ï¼Œåˆ‡æ¢åˆ°å¤‡ç”¨ API")
            print(f"   é”™è¯¯ä¿¡æ¯: {error_message[:200]}...")
            print(f"   å¤‡ç”¨ API Base: {backup_api_base}")
            
            # ä¿å­˜åŸå§‹é…ç½®
            original_api_key = openai.api_key
            original_api_base = openai.api_base
            
            try:
                # åˆ‡æ¢åˆ°å¤‡ç”¨ API
                openai.api_key = backup_api_key
                openai.api_base = backup_api_base
                
                result = openai.ChatCompletion.create(**kwargs)
                print("âœ“ ä½¿ç”¨å¤‡ç”¨ API æˆåŠŸ")
                return result
            except Exception as backup_error:
                print(f"âœ— å¤‡ç”¨ API ä¹Ÿå¤±è´¥: {str(backup_error)[:200]}")
                raise e  # æŠ›å‡ºåŸå§‹é”™è¯¯
            finally:
                # æ¢å¤åŸå§‹é…ç½®
                openai.api_key = original_api_key
                openai.api_base = original_api_base
        else:
            print(f"âš ï¸  é‡åˆ° API é”™è¯¯ ({error_type})ï¼Œä½†æœªé…ç½®å¤‡ç”¨ API")
            print(f"   é”™è¯¯ä¿¡æ¯: {error_message[:200]}...")
            print("   è¯·è®¾ç½®ç¯å¢ƒå˜é‡: BACKUP_OPENAI_API_KEY å’Œ BACKUP_OPENAI_API_BASE")
            raise

def gpt(prompt, model="gpt-4", temperature=0.7, max_tokens=8000, n=1, stop=None) -> list:
    messages = [{"role": "user", "content": prompt}]
    return chatgpt(messages, model=model, temperature=temperature, max_tokens=max_tokens, n=n, stop=stop)
    
def chatgpt(messages, model="gpt-4", temperature=0.7, max_tokens=8000, n=1, stop=None) -> list:
    global completion_tokens, prompt_tokens
    outputs = []
    while n > 0:
        cnt = min(n, 20)
        n -= cnt
        res = completions_with_backoff(model=model, messages=messages, temperature=temperature, max_tokens=max_tokens, n=cnt, stop=stop)
        
        # è®°å½•æœ¬æ¬¡è°ƒç”¨çš„ token ä½¿ç”¨æƒ…å†µ
        current_prompt_tokens = 0
        current_completion_tokens = 0
        if hasattr(res, 'usage'):
            current_prompt_tokens = res.usage.prompt_tokens
            current_completion_tokens = res.usage.completion_tokens
            total_tokens = res.usage.total_tokens if hasattr(res.usage, 'total_tokens') else current_prompt_tokens + current_completion_tokens
        elif isinstance(res, dict) and 'usage' in res:
            current_prompt_tokens = res['usage']['prompt_tokens']
            current_completion_tokens = res['usage']['completion_tokens']
            total_tokens = res['usage'].get('total_tokens', current_prompt_tokens + current_completion_tokens)
        else:
            total_tokens = 0
        
        # æ‰“å° token ä½¿ç”¨æƒ…å†µ
        if total_tokens > 0:
            print(f"ğŸ“Š Token ä½¿ç”¨: prompt={current_prompt_tokens}, completion={current_completion_tokens}, total={total_tokens}")
        
        # æ£€æŸ¥æ˜¯å¦è¢«æˆªæ–­
        truncated_count = 0
        for choice in res.choices:
            finish_reason = None
            if hasattr(choice, 'finish_reason'):
                finish_reason = choice.finish_reason
            elif isinstance(choice, dict) and 'finish_reason' in choice:
                finish_reason = choice['finish_reason']
            
            if finish_reason == 'length':
                truncated_count += 1
        
        if truncated_count > 0:
            print(f"âš ï¸  è­¦å‘Š: {truncated_count}/{cnt} ä¸ªå“åº”å› è¾¾åˆ° max_tokens é™åˆ¶è€Œè¢«æˆªæ–­ (max_tokens={max_tokens})")
        
        # å¤„ç†ä¸åŒçš„å“åº”æ ¼å¼
        parse_failed = False
        for choice in res.choices:
            try:
                content = None
                # å°è¯•æ ‡å‡†çš„ ChatCompletion æ ¼å¼
                if hasattr(choice, 'message') and hasattr(choice.message, 'content'):
                    content = choice.message.content
                # å°è¯•æ—§ç‰ˆ Completion æ ¼å¼
                elif hasattr(choice, 'text'):
                    content = choice.text
                # å°è¯•å­—å…¸æ ¼å¼
                elif isinstance(choice, dict):
                    if 'message' in choice and 'content' in choice['message']:
                        content = choice['message']['content']
                    elif 'text' in choice:
                        content = choice['text']
                    else:
                        print(f"âš ï¸  æœªçŸ¥çš„å“åº”æ ¼å¼ï¼Œchoice keys: {choice.keys()}")
                        print(f"   choice å†…å®¹: {choice}")
                        parse_failed = True
                else:
                    print(f"âš ï¸  æœªçŸ¥çš„ choice ç±»å‹: {type(choice)}")
                    print(f"   choice å†…å®¹: {choice}")
                    parse_failed = True
                
                if content is not None:
                    outputs.append(content)
                else:
                    parse_failed = True
                    
            except Exception as e:
                print(f"âš ï¸  è§£æå“åº”å†…å®¹æ—¶å‡ºé”™: {e}")
                print(f"   choice ç±»å‹: {type(choice)}")
                print(f"   choice å†…å®¹: {choice}")
                parse_failed = True
        
        # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨å¤‡ç”¨ API
        if parse_failed and backup_api_key and backup_api_base:
            print(f"âš ï¸  å“åº”æ ¼å¼è§£æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨å¤‡ç”¨ API")
            print(f"   å¤‡ç”¨ API Base: {backup_api_base}")
            
            # ä¿å­˜åŸå§‹é…ç½®
            original_api_key = openai.api_key
            original_api_base = openai.api_base
            
            try:
                # åˆ‡æ¢åˆ°å¤‡ç”¨ API
                openai.api_key = backup_api_key
                openai.api_base = backup_api_base
                
                # æ¸…ç©ºä¹‹å‰çš„è¾“å‡ºå¹¶é‡æ–°è¯·æ±‚
                outputs = []
                backup_res = openai.ChatCompletion.create(model=model, messages=messages, temperature=temperature, max_tokens=max_tokens, n=cnt, stop=stop)
                
                # è§£æå¤‡ç”¨ API çš„å“åº”
                for choice in backup_res.choices:
                    if hasattr(choice, 'message') and hasattr(choice.message, 'content'):
                        outputs.append(choice.message.content)
                    elif hasattr(choice, 'text'):
                        outputs.append(choice.text)
                    elif isinstance(choice, dict):
                        if 'message' in choice and 'content' in choice['message']:
                            outputs.append(choice['message']['content'])
                        elif 'text' in choice:
                            outputs.append(choice['text'])
                
                res = backup_res  # ä½¿ç”¨å¤‡ç”¨ API çš„å“åº”æ¥è®°å½• token
                print(f"âœ“ ä½¿ç”¨å¤‡ç”¨ API æˆåŠŸï¼Œè·å¾— {len(outputs)} ä¸ªå“åº”")
                
                # é‡æ–°è®¡ç®—å¤‡ç”¨ API çš„ token ä½¿ç”¨æƒ…å†µ
                if hasattr(res, 'usage'):
                    current_prompt_tokens = res.usage.prompt_tokens
                    current_completion_tokens = res.usage.completion_tokens
                elif isinstance(res, dict) and 'usage' in res:
                    current_prompt_tokens = res['usage']['prompt_tokens']
                    current_completion_tokens = res['usage']['completion_tokens']
                
            except Exception as backup_error:
                print(f"âœ— å¤‡ç”¨ API ä¹Ÿå¤±è´¥: {str(backup_error)[:200]}")
                # å¦‚æœå¤‡ç”¨ API ä¹Ÿå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å“åº”çš„å­—ç¬¦ä¸²å½¢å¼
                outputs = [str(choice) for choice in res.choices]
            finally:
                # æ¢å¤åŸå§‹é…ç½®
                openai.api_key = original_api_key
                openai.api_base = original_api_base
        elif parse_failed:
            print("âš ï¸  å“åº”æ ¼å¼è§£æå¤±è´¥ï¼Œä½†æœªé…ç½®å¤‡ç”¨ API")
            print("   è¯·è®¾ç½®ç¯å¢ƒå˜é‡: BACKUP_OPENAI_API_KEY å’Œ BACKUP_OPENAI_API_BASE")
            # ä½¿ç”¨å­—ç¬¦ä¸²å½¢å¼ä½œä¸ºåå¤‡
            outputs.extend([str(choice) for choice in res.choices if choice not in [o for o in outputs]])
        
        # log completion tokens
        completion_tokens += current_completion_tokens
        prompt_tokens += current_prompt_tokens
    
    return outputs
    
def gpt_usage(backend="gpt-4"):
    global completion_tokens, prompt_tokens
    if backend == "gpt-4":
        cost = completion_tokens / 1000 * 0.06 + prompt_tokens / 1000 * 0.03
    elif backend == "gpt-3.5-turbo":
        cost = completion_tokens / 1000 * 0.002 + prompt_tokens / 1000 * 0.0015
    elif backend == "gpt-4o":
        cost = completion_tokens / 1000 * 0.00250 + prompt_tokens / 1000 * 0.01
    return {"completion_tokens": completion_tokens, "prompt_tokens": prompt_tokens, "cost": cost}
